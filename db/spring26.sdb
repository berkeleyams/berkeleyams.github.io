Semester: Spring 2026
Usual location: 939 Evans (for in-person talks) and <a href="https://berkeley.zoom.us/j/98667278310">https://berkeley.zoom.us/j/98667278310</a>
Usual time: 11:10AM-12:00PM
Usual day: Wednesday


Date: 2/4
Host: Lin
Speaker: Anil Damle
Affiliation: Cornell University
Title: Rank-Structured Methods for Data-Driven Problems
<abstract>
Rank-structured matrices are central to many modern applications, including kernel methods in machine learning, numerical PDE solvers, and data analysis. This talk presents two recent advances. First, we address the estimation of high-dimensional covariance matrices from very limited data, a pervasive challenge in fields such as computational fluid dynamics and computational geoscience. Second, we describe how the fast Gauss transform can be extended to a broad class of kernels, yielding a fast kernel transform (FKT) that is practically efficient in low to moderate dimensions. We conclude with remarks on strategies for improving FKT performance in genuinely high-dimensional settings.
</abstract>


Date: 2/11
Host: Ethan
Speaker: Alex Hsu
Affiliation: University of Washington
Title: Bounds and Extremal Examples for the Hot Spots Ratio
<abstract>
The shape of the fluctuations as heat approaches equilibrium in an insulated body are governed by the first Neumann eigenfunction of the Laplacian. Rauch's hot spots conjecture states that the extrema of the first nontrivial Neumann Laplacian eigenfunction for a Lipschitz domain lies on the boundary. While this conjecture is false in general, its failure can be measured by the hot spots ratio, defined as the maximum over the entire domain divided by the maximum on the boundary. We determine the supremum of this quantity over all Lipschitz domains in every dimension $d$ and construct a sequence of sets where the associated hot spots ratios approach this supremum. As $d\to \infty$, this maximal ratio converges to $\sqrt{e}$, which matches the previously best known upper bounds. 
</abstract>

Date: 2/18
Host: Lin
Speaker: Ethan Epperly
Affiliation: UC Berkeley
Title: Sparser, better, faster, stronger: Emerging approaches in the theory and practice of randomized dimensionality reduction
<abstract>
For approaching thirty years, randomized dimensionality reduction techniques have been a core tool in the theory and practice of computation. But despite this robust history, basic questions remain hotly debated: Which dimensionality reduction map should be used? How can the map be adapted to structure in the problem? What is the right theoretical approach to analyzing randomized dimensionality reduction? This talk presents a new approach to the theory of randomized dimensionality reduction under which the core feature of a good dimensionality map is injectivity: It is fine if the map stretches things out a bit as long as it does not annihilate any element of the data space. This new approach yields new analysis of sparse and tensor-structured dimensionality reduction maps that comes closer to describing how these maps behave in practice. This talk is designed for a general audience and assumes no prior familiarity with randomized dimensionality reduction.
</abstract>

Date: 2/25
Host: Lin
Speaker: Zhen Huang
Affiliation: UC Berkeley
Title: 
<abstract>
</abstract>


Date: 3/11
Host: Lin
Speaker: Yu Tong
Affiliation: Duke University
Title: 
<abstract>
</abstract>

Date: 3/18
Host: Ethan
Speaker: Heather Wilber
Affiliation: University of Washington
Title: 
<abstract>
</abstract>

Date: 4/6 
Note: Special time and place
Host: Lin
Speaker: Nick Trefethen
Affiliation: Harvard University
Title: Quadrature = rational approximation
<abstract>
Whenever you see a string of quadrature nodes, you can consider it
as a branch cut defined by the poles of a rational approximation to
the Cauchy transform of a weight function.  The aim of this talk
is to explain this strange statement and show how it opens the
way to calculation of targeted quadrature formulas for all kinds
of applications.  Gauss quadrature is an example, but it is just
the starting point, and many more examples will be shown.  I hope
this talk will change your understanding of quadrature formulas.
This is joint work with Andrew Horning.
</abstract>

Date: 4/8
Host: Franziska
Speaker: Yekaterina Epshteyn
Affiliation: The University of Utah
Title: 
<abstract>
</abstract>


Date: 4/15
Host: Lin
Speaker: Molei Tao
Affiliation: Georgia Tech
Title: 
<abstract>
</abstract>


Date: 4/29
Host: Ethan
Speaker: Haoxuan Chen
Affiliation: Stanford
Title: 
<abstract>
</abstract>
