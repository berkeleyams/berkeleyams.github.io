<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
	<title>UCB/LBL Applied Math Seminar &#8211; Yuan Yao &#8211; Rethinking Generalization and Robustness in Neural Networks: Breiman’s Dilemma and Huber’s Model</title>
	<base href="https://berkeleyams.github.io/" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" type="text/css" media="screen, projection" href="default.css" />
	<meta name="description" content="A joint seminar series covering a wide variety of topics in
	applied mathematics, PDEs, and scientific computation." />
	<meta name="keywords" content="Berkeley, applied math, applied, mathematics, LBL, LBNL, Lawrence, National, Lab, Laboratory, seminar, talks, PDE, numerics, numerical, mathematical, methods, computation, fluid, mechanics, dynamics, simulation, scientific" />
	<meta name="author" content="Chris Rycroft" />
	<meta name="robots" content="all" />
	<link href="index.html" rel="start" title="Seminar Index" />
</head>
<body>
	<div id="container">
		<div id="head">
			<div id="maintitle">
				<h1><a href="index.html">Applied Mathematics Seminar</a></h1>
			<h2>UC Berkeley / Lawrence Berkeley Laboratory</h2>
			</div>
<!--
			<h3>Organized by <a href="https://math.berkeley.edu/~linlin/">Lin Lin</a>,<br/><a href="http://math.lbl.gov/~mjzahr/">Matthew J. Zahr</a>,<br/> and <a href="http://persson.berkeley.edu/">Per-Olof Persson</a><br/> </h3>
-->
			<h3>Organized by <a href="https://math.berkeley.edu/people/faculty/sun-ica-ani-0">Suncica Canic</a>,<br/><a href="https://math.berkeley.edu/~difang/">Di Fang</a>,<br/><a href="https://math.berkeley.edu/~linlin/">Lin Lin</a>,<br/> and <a href="http://persson.berkeley.edu/">Per-Olof Persson</a> <br/>  </h3>
		</div>
<h4 class="top">Rethinking Generalization and Robustness in Neural Networks: Breiman’s Dilemma and Huber’s Model</h4>
<h5><b>Yuan Yao, Hong Kong University of Science and Technology</b></h5>
<h5>November 1st, 2018 at 11:00AM&ndash;12:00PM in Evans 732</h5>
<p>We approach the following two fundamental problems in deep learning: (a) how can over-parameterized models generalize well in neural networks?
(b) how does deep learning achieve the robustness against adversarial samples?
</p><p>
For problem (a), Max-Margin has been an important strategy since perceptrons in machine learning for the purpose of boosting the robustness of 
classifiers toward a good generalization ability, which experienced a renaissance lately to explain the success in deep learning. However, Leo Breiman 
pointed out a dilemma in 1999 that margin increase over training data results in a decrease in generalization performance, that will be shown ubiquitous in 
neural networks as well. In particular, we propose a new method to explain the mechanism of Breiman’s Dilemma, using phase transitions of normalized 
margin dynamics.
</p><p>
For problem (b), we revisit Huber’s contamination model in robust statistics, from a perspective of generative adversarial networks (GAN). When the outlier 
examples are fully agnostic in distributions, GANs are shown in both theory and experiment to achieve robust estimates at information-theoretically optimal rates, 
equivalent in statistical precision to the Tukey median estimate that is NP-hard to compute though. GANs may have wider adaptation than other polynomial 
algorithms proposed lately based on moment methods. Hence, by playing some zero-sum differential games, GANs provides us provable guarantees on 
robustness under Huber’s model. 
</p>

<br />
	<div id="foot">
		<div class="links">
			<a href="http://math.berkeley.edu/">UCB Math</a> |
			<a href="http://math.lbl.gov/">LBL Math</a>
		</div>
	</div>
</div>
</body>
</html>
