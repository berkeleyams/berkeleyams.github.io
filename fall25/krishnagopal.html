<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
	<title>UCB/LBL Applied Math Seminar &#8211; Sanjukta Krishnagopal &#8211; Graph signal processing: from machine learning theory to simplicial complexes</title>
	<base href="https://berkeleyams.lbl.gov/" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" type="text/css" media="screen, projection" href="default.css" />
	<meta name="description" content="A joint seminar series covering a wide variety of topics in
	applied mathematics, PDEs, and scientific computation." />
	<meta name="keywords" content="Berkeley, applied math, applied, mathematics, LBL, LBNL, Lawrence, National, Lab, Laboratory, seminar, talks, PDE, numerics, numerical, mathematical, methods, computation, fluid, mechanics, dynamics, simulation, scientific" />
	<meta name="author" content="Chris Rycroft" />
	<meta name="robots" content="all" />
	<link href="index.html" rel="start" title="Seminar Index" />
</head>
<body>
	<div id="container">
		<div id="head">
			<div id="maintitle">
				<h1><a href="index.html">Applied Mathematics Seminar</a></h1>
			<h2>UC Berkeley / Lawrence Berkeley Laboratory</h2>
			</div>
			<h3>Organized by <a href=" ">Ethan Epperly</a >, <a href="https://math.berkeley.edu/~linlin/">Lin Lin</a >,<br/><a href="https://quantumtative.github.io/">Michael Lindsey</a >,<br/>and <a href="https://sites.google.com/berkeley.edu/fweber">Franziska Weber</a ></h3>
		</div>
<h4 class="top">Graph signal processing: from machine learning theory to simplicial complexes</h4>
<h5><b>Sanjukta Krishnagopal, UCSB</b></h5>
<h5>9/17, 2025 at 11:10AM-12:00PM in 939 Evans (for in-person talks) and <a href="https://berkeley.zoom.us/j/98667278310">https://berkeley.zoom.us/j/98667278310</a></h5>
<p>In this talk I will discuss some aspects at the intersection of mathematics, machine learning, and network science.
First, I will discuss some results in graph machine learning. I will present some theoretical results on how learning evolves when training graph neural networks in the wide limit via neural tangent kernels, using graphons - a graph limiting object, or a graph with infinitely many nodes. I show how these results can be used perform transfer learning on large graphs with rigorous guarantees of performance. 
Then, I will discuss some work on higher-order networks: simplicial complexes - that can capture simultaneous many-body interactions, unlike conventional pairwise graphs. I will present some recent results on spectral theory of simplicial complexes using Hodge theory, and discuss how these results can be used to study how signals/information spreads on these higher-order networks.
</p>

<br />
	<div id="foot">
		<div class="links">
			<a href="http://math.berkeley.edu/">UCB Math</a> |
			<a href="http://math.lbl.gov/">LBL Math</a>
		</div>
	</div>
</div>
</body>
</html>
