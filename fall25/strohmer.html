<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
	<title>UCB/LBL Applied Math Seminar &#8211; Thomas Strohmer &#8211; Can AI Truly Forget? A Mathematical Framework for Machine Unlearning</title>
	<base href="https://berkeleyams.lbl.gov/" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" type="text/css" media="screen, projection" href="default.css" />
	<meta name="description" content="A joint seminar series covering a wide variety of topics in
	applied mathematics, PDEs, and scientific computation." />
	<meta name="keywords" content="Berkeley, applied math, applied, mathematics, LBL, LBNL, Lawrence, National, Lab, Laboratory, seminar, talks, PDE, numerics, numerical, mathematical, methods, computation, fluid, mechanics, dynamics, simulation, scientific" />
	<meta name="author" content="Chris Rycroft" />
	<meta name="robots" content="all" />
	<link href="index.html" rel="start" title="Seminar Index" />
</head>
<body>
	<div id="container">
		<div id="head">
			<div id="maintitle">
				<h1><a href="index.html">Applied Mathematics Seminar</a></h1>
			<h2>UC Berkeley / Lawrence Berkeley Laboratory</h2>
			</div>
			<h3>Organized by <a href=" ">Ethan Epperly</a >, <a href="https://math.berkeley.edu/~linlin/">Lin Lin</a >,<br/><a href="https://quantumtative.github.io/">Michael Lindsey</a >,<br/>and <a href="https://sites.google.com/berkeley.edu/fweber">Franziska Weber</a ></h3>
		</div>
<h4 class="top">Can AI Truly Forget? A Mathematical Framework for Machine Unlearning</h4>
<h5><b>Thomas Strohmer, UC Davis</b></h5>
<h5>12/3, 2025 at 11:10AM-12:00PM in 939 Evans (for in-person talks) and <a href="https://berkeley.zoom.us/j/98667278310">https://berkeley.zoom.us/j/98667278310</a></h5>
<p>As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance. Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs).  However, existing unlearning methods often severely degrade model performance by removing more information than necessary when attempting to "forget" specific data. We introduce a mathematical framework based on information-theoretic regularization that can accommodate different types of machine unlearning, such as feature unlearning and data point unlearning. Our theoretical analysis reveals intriguing connections between machine unlearning, information theory, optimal transport, and extremal sigma algebras. For LLMs, we propose Forgetting-MarI, an unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained.  Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks.  This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness. We will also discuss applications in machine learning driven scientific discovery. This is joint work with Shizhou Xu, Yuan Ni, and Stefan Broecker.
</p>

<br />
	<div id="foot">
		<div class="links">
			<a href="http://math.berkeley.edu/">UCB Math</a> |
			<a href="http://math.lbl.gov/">LBL Math</a>
		</div>
	</div>
</div>
</body>
</html>
