<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
	<title>UCB/LBL Applied Math Seminar &#8211; Ethan Epperly &#8211; Sparser, better, faster, stronger: Emerging approaches in the theory and practice of randomized dimensionality reduction</title>
	<base href="https://berkeleyams.lbl.gov/" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" type="text/css" media="screen, projection" href="default.css" />
	<meta name="description" content="A joint seminar series covering a wide variety of topics in
	applied mathematics, PDEs, and scientific computation." />
	<meta name="keywords" content="Berkeley, applied math, applied, mathematics, LBL, LBNL, Lawrence, National, Lab, Laboratory, seminar, talks, PDE, numerics, numerical, mathematical, methods, computation, fluid, mechanics, dynamics, simulation, scientific" />
	<meta name="author" content="Chris Rycroft" />
	<meta name="robots" content="all" />
	<link href="index.html" rel="start" title="Seminar Index" />
</head>
<body>
	<div id="container">
		<div id="head">
			<div id="maintitle">
				<h1><a href="index.html">Applied Mathematics Seminar</a></h1>
			<h2>UC Berkeley / Lawrence Berkeley Laboratory</h2>
			</div>
			<h3>Organized by <a href=" ">Ethan Epperly</a >, <a href="https://math.berkeley.edu/~linlin/">Lin Lin</a >,<br/><a href="https://quantumtative.github.io/">Michael Lindsey</a >,<br/>and <a href="https://sites.google.com/berkeley.edu/fweber">Franziska Weber</a ></h3>
		</div>
<h4 class="top">Sparser, better, faster, stronger: Emerging approaches in the theory and practice of randomized dimensionality reduction</h4>
<h5><b>Ethan Epperly, UC Berkeley</b></h5>
<h5>2/18, 2026 at 11:10AM-12:00PM in 939 Evans (for in-person talks) and <a href="https://berkeley.zoom.us/j/98667278310">https://berkeley.zoom.us/j/98667278310</a></h5>
<p>For approaching thirty years, randomized dimensionality reduction techniques have been a core tool in the theory and practice of computation. But despite this robust history, basic questions remain hotly debated: Which dimensionality reduction map should be used? How can the map be adapted to structure in the problem? What is the right theoretical approach to analyzing randomized dimensionality reduction? This talk presents a new approach to the theory of randomized dimensionality reduction under which the core feature of a good dimensionality map is injectivity: It is fine if the map stretches things out a bit as long as it does not annihilate any element of the data space. This new approach yields new analysis of sparse and tensor-structured dimensionality reduction maps that comes closer to describing how these maps behave in practice. This talk is designed for a general audience and assumes no prior familiarity with randomized dimensionality reduction.
</p>

<br />
	<div id="foot">
		<div class="links">
			<a href="http://math.berkeley.edu/">UCB Math</a> |
			<a href="http://math.lbl.gov/">LBL Math</a>
		</div>
	</div>
</div>
</body>
</html>
